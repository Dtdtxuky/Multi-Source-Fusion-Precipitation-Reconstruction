2024-11-19 20:11:35,849 train INFO: Building config ...
2024-11-19 20:11:35,850 train INFO: Building dataloaders ...
2024-11-19 20:11:43,227 train INFO: Train dataloaders build complete
2024-11-19 20:11:43,280 train INFO: Valid dataloaders build complete
2024-11-19 20:11:43,280 train INFO: Building models ...
2024-11-19 20:11:46,891 train INFO: finetune checkpoint path not exist
2024-11-19 20:11:47,475 train INFO: params autoencoder_kl: 83607691
2024-11-19 20:11:47,475 train INFO: params lpipsWithDisc: 2763586
2024-11-19 20:11:47,475 train INFO: begin training ...
2024-11-19 20:12:48,358 train INFO: Epoch [2.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0875 (-0.0875, -0.0875)  val/total_loss: 14339.4644 (14339.4644, 14339.4644)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 88.7554 (88.7554, 88.7554)  val/nll_loss: 14339.4644 (14339.4644, 14339.4644)  val/rec_loss: 0.2188 (0.2188, 0.2188)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0875 (0.0875, 0.0875)  MSE: 0.1021 (0.1021, 0.1021)
2024-11-19 20:13:10,324 train INFO: Epoch [3.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0861 (-0.0861, -0.0861)  val/total_loss: 12438.7847 (12438.7847, 12438.7847)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 125.4178 (125.4178, 125.4178)  val/nll_loss: 12438.7847 (12438.7847, 12438.7847)  val/rec_loss: 0.1898 (0.1898, 0.1898)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0861 (0.0861, 0.0861)  MSE: 0.0789 (0.0789, 0.0789)
2024-11-19 20:13:30,292 train INFO: Epoch [4.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0861 (-0.0861, -0.0861)  val/total_loss: 9063.2734 (9063.2734, 9063.2734)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 190.5775 (190.5775, 190.5775)  val/nll_loss: 9063.2734 (9063.2734, 9063.2734)  val/rec_loss: 0.1383 (0.1383, 0.1383)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0861 (0.0861, 0.0861)  MSE: 0.0696 (0.0696, 0.0696)
2024-11-19 20:13:48,739 train INFO: Epoch [5.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0867 (-0.0867, -0.0867)  val/total_loss: 7410.3030 (7410.3030, 7410.3030)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 294.1771 (294.1771, 294.1771)  val/nll_loss: 7410.3025 (7410.3025, 7410.3025)  val/rec_loss: 0.1131 (0.1131, 0.1131)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0867 (0.0867, 0.0867)  MSE: 0.0700 (0.0700, 0.0700)
2024-11-19 20:14:01,653 train INFO: Epoch [6.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 6613.8647 (6613.8647, 6613.8647)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 434.0833 (434.0833, 434.0833)  val/nll_loss: 6613.8643 (6613.8643, 6613.8643)  val/rec_loss: 0.1009 (0.1009, 0.1009)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0592 (0.0592, 0.0592)
2024-11-19 20:14:22,453 train INFO: Epoch [7.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 5686.8923 (5686.8923, 5686.8923)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 610.1202 (610.1202, 610.1202)  val/nll_loss: 5686.8918 (5686.8918, 5686.8918)  val/rec_loss: 0.0868 (0.0868, 0.0868)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0541 (0.0541, 0.0541)
2024-11-19 20:14:41,167 train INFO: Epoch [8.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 5415.0955 (5415.0955, 5415.0955)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 825.1370 (825.1370, 825.1370)  val/nll_loss: 5415.0945 (5415.0945, 5415.0945)  val/rec_loss: 0.0826 (0.0826, 0.0826)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0530 (0.0530, 0.0530)
2024-11-19 20:14:58,426 train INFO: Epoch [9.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0870 (-0.0870, -0.0870)  val/total_loss: 5365.6345 (5365.6345, 5365.6345)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 1078.9150 (1078.9150, 1078.9150)  val/nll_loss: 5365.6335 (5365.6335, 5365.6335)  val/rec_loss: 0.0819 (0.0819, 0.0819)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0870 (0.0870, 0.0870)  MSE: 0.0491 (0.0491, 0.0491)
2024-11-19 20:15:16,821 train INFO: Epoch [10.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0869 (-0.0869, -0.0869)  val/total_loss: 4962.4153 (4962.4153, 4962.4153)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 1381.7511 (1381.7511, 1381.7511)  val/nll_loss: 4962.4141 (4962.4141, 4962.4141)  val/rec_loss: 0.0757 (0.0757, 0.0757)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0869 (0.0869, 0.0869)  MSE: 0.0437 (0.0437, 0.0437)
2024-11-19 20:15:29,436 train INFO: [20/2/200000]  lr: 1.09405e-06  eta: 25 days, 16:27:27  iter_time: 9.100  data: 5.646  memory: 47934  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: -0.0867 (-0.0866, -0.0866)  train/logits_fake: -0.0869 (-0.0869, -0.0869)  train/total_loss: 5227.2678 (5457.6149, 5459.6462)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 1438.5637 (1520.9900, 1603.4164)  train/nll_loss: 5227.2664 (5457.6133, 5459.6445)  train/rec_loss: 0.0798 (0.0833, 0.0833)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: 0.0869 (0.0869, 0.0869)
2024-11-19 20:15:35,096 train INFO: Epoch [11.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0869 (-0.0869, -0.0869)  val/total_loss: 4665.0793 (4665.0793, 4665.0793)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 1730.7281 (1730.7281, 1730.7281)  val/nll_loss: 4665.0776 (4665.0776, 4665.0776)  val/rec_loss: 0.0712 (0.0712, 0.0712)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0869 (0.0869, 0.0869)  MSE: 0.0436 (0.0436, 0.0436)
2024-11-19 20:15:55,397 train INFO: Epoch [12.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 4576.8411 (4576.8411, 4576.8411)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2119.3027 (2119.3027, 2119.3027)  val/nll_loss: 4576.8389 (4576.8389, 4576.8389)  val/rec_loss: 0.0698 (0.0698, 0.0698)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0494 (0.0494, 0.0494)
2024-11-19 20:16:07,503 train INFO: Epoch [13.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0870 (-0.0870, -0.0870)  val/total_loss: 4492.4460 (4492.4460, 4492.4460)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2540.9463 (2540.9463, 2540.9463)  val/nll_loss: 4492.4436 (4492.4436, 4492.4436)  val/rec_loss: 0.0685 (0.0685, 0.0685)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0870 (0.0870, 0.0870)  MSE: 0.0453 (0.0453, 0.0453)
2024-11-19 20:16:20,677 train INFO: Epoch [14.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 4281.7183 (4281.7183, 4281.7183)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2975.3378 (2975.3378, 2975.3378)  val/nll_loss: 4281.7153 (4281.7153, 4281.7153)  val/rec_loss: 0.0653 (0.0653, 0.0653)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0399 (0.0399, 0.0399)
2024-11-19 20:16:38,664 train INFO: Epoch [15.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 4088.1709 (4088.1709, 4088.1709)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 3398.9967 (3398.9967, 3398.9967)  val/nll_loss: 4088.1676 (4088.1676, 4088.1676)  val/rec_loss: 0.0624 (0.0624, 0.0624)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0359 (0.0359, 0.0359)
2024-11-19 20:16:56,222 train INFO: Epoch [16.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 4073.8035 (4073.8035, 4073.8035)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 3775.0856 (3775.0856, 3775.0856)  val/nll_loss: 4073.7997 (4073.7997, 4073.7997)  val/rec_loss: 0.0622 (0.0622, 0.0622)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0364 (0.0364, 0.0364)
2024-11-19 20:17:09,272 train INFO: Epoch [17.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 4011.3141 (4011.3141, 4011.3141)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 4068.6091 (4068.6091, 4068.6091)  val/nll_loss: 4011.3101 (4011.3101, 4011.3101)  val/rec_loss: 0.0612 (0.0612, 0.0612)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0342 (0.0342, 0.0342)
2024-11-19 20:17:26,902 train INFO: Epoch [18.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3942.9509 (3942.9509, 3942.9509)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 4229.7183 (4229.7183, 4229.7183)  val/nll_loss: 3942.9467 (3942.9467, 3942.9467)  val/rec_loss: 0.0602 (0.0602, 0.0602)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0344 (0.0344, 0.0344)
2024-11-19 20:17:38,533 train INFO: Epoch [19.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3787.4353 (3787.4353, 3787.4353)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 4191.8328 (4191.8328, 4191.8328)  val/nll_loss: 3787.4312 (3787.4312, 3787.4312)  val/rec_loss: 0.0578 (0.0578, 0.0578)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0304 (0.0304, 0.0304)
2024-11-19 20:17:57,437 train INFO: Epoch [20.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3635.7225 (3635.7225, 3635.7225)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 4008.9419 (4008.9419, 4008.9419)  val/nll_loss: 3635.7185 (3635.7185, 3635.7185)  val/rec_loss: 0.0555 (0.0555, 0.0555)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0285 (0.0285, 0.0285)
2024-11-19 20:18:10,240 train INFO: [40/2/200000]  lr: 1.19305e-06  eta: 22 days, 3:29:42  iter_time: 8.290  data: 5.111  memory: 47934  train/disc_loss: 0.0000 (0.0000, 0.0000)  train/logits_real: -0.0866 (-0.0866, -0.0865)  train/logits_fake: -0.0870 (-0.0870, -0.0870)  train/total_loss: 4208.1453 (4426.9431, 4645.7410)  train/logvar: 0.0000 (0.0000, 0.0000)  train/kl_loss: 2480.2815 (2900.9144, 2689.3053)  train/nll_loss: 4208.1421 (4426.9402, 4645.7383)  train/rec_loss: 0.0642 (0.0675, 0.0709)  train/d_weight: 5000.0000 (5000.0000, 5000.0000)  train/disc_factor: 0.0000 (0.0000, 0.0000)  train/g_loss: 0.0870 (0.0870, 0.0870)
2024-11-19 20:18:15,624 train INFO: Epoch [21.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0870 (-0.0870, -0.0870)  val/total_loss: 3606.6884 (3606.6884, 3606.6884)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 3774.9822 (3774.9822, 3774.9822)  val/nll_loss: 3606.6846 (3606.6846, 3606.6846)  val/rec_loss: 0.0550 (0.0550, 0.0550)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0870 (0.0870, 0.0870)  MSE: 0.0274 (0.0274, 0.0274)
2024-11-19 20:18:35,284 train INFO: Epoch [22.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3610.9296 (3610.9296, 3610.9296)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 3467.9452 (3467.9452, 3467.9452)  val/nll_loss: 3610.9261 (3610.9261, 3610.9261)  val/rec_loss: 0.0551 (0.0551, 0.0551)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0258 (0.0258, 0.0258)
2024-11-19 20:18:52,728 train INFO: Epoch [23.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0870 (-0.0870, -0.0870)  val/total_loss: 3609.3384 (3609.3384, 3609.3384)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 3161.9257 (3161.9257, 3161.9257)  val/nll_loss: 3609.3352 (3609.3352, 3609.3352)  val/rec_loss: 0.0551 (0.0551, 0.0551)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0870 (0.0870, 0.0870)  MSE: 0.0234 (0.0234, 0.0234)
2024-11-19 20:19:11,352 train INFO: Epoch [24.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3437.8401 (3437.8401, 3437.8401)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2992.5203 (2992.5203, 2992.5203)  val/nll_loss: 3437.8372 (3437.8372, 3437.8372)  val/rec_loss: 0.0525 (0.0525, 0.0525)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0223 (0.0223, 0.0223)
2024-11-19 20:19:29,186 train INFO: Epoch [25.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3457.4814 (3457.4814, 3457.4814)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2901.5332 (2901.5332, 2901.5332)  val/nll_loss: 3457.4785 (3457.4785, 3457.4785)  val/rec_loss: 0.0528 (0.0528, 0.0528)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0228 (0.0228, 0.0228)
2024-11-19 20:19:42,490 train INFO: Epoch [26.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0870 (-0.0870, -0.0870)  val/total_loss: 3332.9677 (3332.9677, 3332.9677)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2812.4692 (2812.4692, 2812.4692)  val/nll_loss: 3332.9648 (3332.9648, 3332.9648)  val/rec_loss: 0.0509 (0.0509, 0.0509)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0870 (0.0870, 0.0870)  MSE: 0.0208 (0.0208, 0.0208)
2024-11-19 20:20:02,927 train INFO: Epoch [27.0](val stats)  val/disc_loss: 0.0000 (0.0000, 0.0000)  val/logits_real: -0.0868 (-0.0868, -0.0868)  val/logits_fake: -0.0871 (-0.0871, -0.0871)  val/total_loss: 3301.5669 (3301.5669, 3301.5669)  val/logvar: 0.0000 (0.0000, 0.0000)  val/kl_loss: 2758.3380 (2758.3380, 2758.3380)  val/nll_loss: 3301.5642 (3301.5642, 3301.5642)  val/rec_loss: 0.0504 (0.0504, 0.0504)  val/d_weight: 0.0000 (0.0000, 0.0000)  val/disc_factor: 0.0000 (0.0000, 0.0000)  val/g_loss: 0.0871 (0.0871, 0.0871)  MSE: 0.0196 (0.0196, 0.0196)
